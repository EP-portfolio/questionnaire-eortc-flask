/**
 * Gestionnaire de reconnaissance vocale pour l'application Flask
 * Support Web Speech API (Chrome/Edge) et fallback (Firefox/Safari)
 * Version optimis√©e avec :
 * - Arr√™t automatique de l'audio quand l'utilisateur parle
 * - Filtrage des r√©sultats parasites
 * - Pause/reprise automatique pendant lecture audio
 * - Am√©lioration de la reconnaissance (moins de r√©p√©titions)
 */

class SpeechRecognitionManager {
    constructor() {
        this.recognition = null;
        this.isListening = false;
        this.isWebSpeechSupported = false;
        this.mediaRecorder = null;
        this.audioChunks = [];
        this.shouldRestart = false;
        this.processingResponse = false;
        this.isPaused = false; // ‚úÖ Pour pause/reprise

        this.init();
    }

    // ‚úÖ NOUVEAU : Mettre en pause la reconnaissance
    pauseRecognition() {
        if (this.recognition && !this.isPaused) {
            console.log('‚è∏Ô∏è Reconnaissance vocale mise en pause');
            this.isPaused = true;
            // On ne stop pas, juste on ignore les r√©sultats pendant la pause
        }
    }

    // ‚úÖ NOUVEAU : Reprendre la reconnaissance
    resumeRecognition() {
        if (this.recognition && this.isPaused) {
            console.log('‚ñ∂Ô∏è Reconnaissance vocale reprise');
            this.isPaused = false;
        }
    }

    // ‚úÖ NOUVEAU : Gestion intelligente de l'arr√™t audio (Chrome uniquement)
    handleAudioStop() {
        console.log('üîá Audio arr√™t√© - Gestion Chrome (logique existante pr√©serv√©e)');

        // ‚úÖ PR√âSERVER : Logique Chrome existante qui fonctionne
        if (this.recognition && !this.isPaused) {
            console.log('üåê Chrome : Mise en pause simple (logique existante)');
            this.pauseRecognition();

            // Red√©marrage automatique apr√®s 2 secondes (logique existante)
            setTimeout(() => {
                if (this.isPaused) {
                    console.log('üåê Chrome : Reprise automatique (logique existante)');
                    this.resumeRecognition();
                }
            }, 2000);
        }
    }

    init() {
        this.isWebSpeechSupported = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;

        if (this.isWebSpeechSupported) {
            this.initWebSpeech();
        } else {
            console.log('Web Speech API non support√©e, utilisation du mode fallback');
        }
    }

    initWebSpeech() {
        try {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            this.recognition = new SpeechRecognition();

            // ‚úÖ PARAM√àTRES OPTIMIS√âS
            this.recognition.continuous = true;
            this.recognition.interimResults = true; // ‚úÖ Activ√© pour meilleure r√©activit√©
            this.recognition.lang = 'fr-FR';
            this.recognition.maxAlternatives = 1;

            this.recognition.onstart = () => {
                console.log('Reconnaissance vocale d√©marr√©e');
                this.isListening = true;
                this.updateUI('listening');
            };

            this.recognition.onresult = (event) => {
                // ‚úÖ V√âRIFIER isPaused IMM√âDIATEMENT
                if (this.isPaused) {
                    console.log('‚è∏Ô∏è Reconnaissance en pause - R√©sultat ignor√© (onresult)');
                    return; // Ignorer TOUS les r√©sultats pendant la pause
                }

                console.log('DEBUG: onresult d√©clench√©', event);

                const last = event.results.length - 1;
                const result = event.results[last];
                const transcript = result[0].transcript.trim();
                const confidence = result[0].confidence;
                const isFinal = result.isFinal;

                console.log('DEBUG: R√©sultat', isFinal ? 'FINAL' : 'INTERIM', ':', transcript, 'Confiance:', confidence);

                // ‚úÖ AM√âLIORATION : Accepter r√©sultats finaux OU interm√©diaires avec haute confiance
                if (isFinal || (confidence > 0.7 && transcript.length <= 20)) {
                    this.handleSpeechResult(transcript, confidence);
                }
            };

            this.recognition.onerror = (event) => {
                // ‚úÖ Ne pas logger l'erreur "network" (timeout normal)
                if (event.error !== 'network') {
                    console.error('Erreur reconnaissance:', event.error);
                }
                this.handleSpeechError(event.error);
            };

            this.recognition.onend = () => {
                console.log('Reconnaissance vocale termin√©e');
                this.isListening = false;
                this.updateUI('stopped');

                if (this.shouldRestart && !this.isListening) {
                    console.log('Red√©marrage automatique de l\'√©coute...');
                    setTimeout(() => {
                        if (this.shouldRestart && !this.isListening) {
                            this.startContinuousSpeech();
                        }
                    }, 1000);
                }
            };

        } catch (error) {
            console.error('Erreur initialisation Web Speech:', error);
            this.isWebSpeechSupported = false;
        }
    }

    startContinuousSpeech() {
        if (!this.isWebSpeechSupported) {
            alert('Reconnaissance vocale continue non disponible sur ce navigateur');
            return;
        }

        if (this.isListening) {
            this.stopContinuousSpeech();
            return;
        }

        this.shouldRestart = true;

        try {
            this.recognition.start();
            this.updateUI('active');
            console.log('√âcoute continue d√©marr√©e');
        } catch (error) {
            console.error('Erreur d√©marrage reconnaissance:', error);
            alert('Erreur : Impossible de d√©marrer la reconnaissance vocale');
        }
    }


    stopContinuousSpeech() {
        this.shouldRestart = false;

        if (this.recognition && this.isListening) {
            this.recognition.stop();
        }
        this.isListening = false;
        this.updateUI('stopped');
        console.log('√âcoute continue arr√™t√©e');
    }

    handleSpeechResult(transcript, confidence) {
        console.log('DEBUG: handleSpeechResult appel√© avec:', transcript);

        // ============================================
        // üõ°Ô∏è FILTRAGE DES R√âSULTATS PARASITES
        // ============================================

        // Nettoyer le transcript
        const cleanTranscript = transcript.trim();

        // 1Ô∏è‚É£ FILTRE : Rejeter si le texte contient "question" suivi d'un chiffre
        const questionPattern = /question\s+\d+/i;
        if (questionPattern.test(cleanTranscript)) {
            console.log('‚ö†Ô∏è REJET√â : Texte contient "question X" - probablement l\'audio de la question');
            console.log(`   Texte rejet√© : "${cleanTranscript}"`);
            return;
        }


        // 2Ô∏è‚É£ FILTRE : Rejeter si le texte est trop long (> 12 caract√®res)
        // ‚úÖ AM√âLIORATION : Limite augment√©e √† 15 pour accepter plus facilement
        if (cleanTranscript.length > 20) {
            console.log(`‚ö†Ô∏è REJET√â : Texte trop long (${cleanTranscript.length} caract√®res)`);
            console.log(`   Texte rejet√© : "${cleanTranscript.substring(0, 50)}..."`);
            return;
        }

        // 3Ô∏è‚É£ FILTRE : Rejeter si le texte est vide
        if (cleanTranscript.length === 0) {
            console.log('‚ö†Ô∏è REJET√â : Texte vide');
            return;
        }

        // ‚úÖ Le texte a pass√© tous les filtres
        console.log(`‚úÖ ACCEPT√â : "${cleanTranscript}" (${cleanTranscript.length} caract√®res)`);

        // ============================================
        // FIN FILTRAGE
        // ============================================

        // ‚úÖ Arr√™ter l'audio de la question d√®s que l'utilisateur parle
        if (window.stopAudioOnSpeech) {
            console.log('üîá D√©tection de parole - Arr√™t de l\'audio de la question');
            window.stopAudioOnSpeech();
        }

        // Afficher le transcript
        this.updateTranscript(cleanTranscript);

        // ‚úÖ AM√âLIORATION : D√©lai r√©duit de 500ms √† 200ms
        setTimeout(() => {
            this.processVoiceResponse(cleanTranscript);
        }, 200);
    }

    handleSpeechError(error) {
        let message = '';

        switch (error) {
            case 'no-speech':
                message = 'Aucune parole d√©tect√©e. Veuillez r√©essayer.';
                break;
            case 'audio-capture':
                message = 'Erreur : Microphone non disponible';
                break;
            case 'not-allowed':
                message = 'Erreur : Acc√®s au microphone refus√©';
                break;
            case 'network':
                // NE PAS afficher de message - red√©marrage auto
                console.log('‚ö†Ô∏è Timeout r√©seau - red√©marrage auto');
                return; // Ne pas afficher d'erreur √† l'utilisateur
            case 'aborted':
                return;
            default:
                message = `Erreur reconnaissance : ${error}`;
        }

        if (message) {
            this.showError(message);
        }
    }

    async processVoiceResponse(transcript) {
        console.log('DEBUG: processVoiceResponse appel√© avec:', transcript);

        if (this.processingResponse) {
            console.log('DEBUG: D√©j√† en cours de traitement, ignor√©');
            return;
        }

        this.processingResponse = true;

        try {
            if (!transcript || transcript.trim() === '') {
                console.log('DEBUG: Transcript vide, arr√™t');
                this.showError('Aucune parole d√©tect√©e. Veuillez parler plus fort.');
                return;
            }

            const response = await fetch('/api/process_voice', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    session_id: window.sessionId,
                    question_num: window.currentQuestion,
                    transcript: transcript
                })
            });

            const result = await response.json();

            if (result.valid) {
                this.showSuccess(result.response_text);

                if (result.is_complete) {
                    setTimeout(() => {
                        window.location.href = `/resultat/${window.sessionId}`;
                    }, 2000);
                } else {
                    setTimeout(() => {
                        window.loadQuestion(result.next_question);
                    }, 2000);
                }
            } else {
                this.showError(result.error || 'R√©ponse non reconnue');
                this.showSuggestions(result.suggestions || []);
            }

        } catch (error) {
            console.error('Erreur traitement vocal:', error);
            this.showError('Erreur : Impossible de traiter la r√©ponse');
        } finally {
            setTimeout(() => {
                this.processingResponse = false;
            }, 500);
        }
    }

    updateUI(state) {
        const statusIndicator = document.getElementById('status-indicator');
        const statusText = document.getElementById('status-text');
        const startBtn = document.getElementById('start-speech-btn');
        const stopBtn = document.getElementById('stop-speech-btn');

        if (!statusIndicator || !statusText) return;

        switch (state) {
            case 'active':
                statusIndicator.innerHTML = '<i class="fas fa-microphone"></i>';
                statusIndicator.style.background = 'rgba(255, 255, 255, 0.3)';
                statusText.textContent = 'üé§ Micro actif - Parlez naturellement';
                if (startBtn) startBtn.style.display = 'none';
                if (stopBtn) stopBtn.style.display = 'inline-flex';
                break;

            case 'listening':
                statusIndicator.innerHTML = '<i class="fas fa-circle"></i>';
                statusIndicator.style.background = 'rgba(255, 0, 0, 0.3)';
                statusText.textContent = 'üî¥ √âcoute en cours...';
                break;

            case 'stopped':
                statusIndicator.innerHTML = '<i class="fas fa-microphone"></i>';
                statusIndicator.style.background = 'rgba(255, 255, 255, 0.2)';
                statusText.textContent = 'Cliquez pour activer le micro continu';
                if (startBtn) startBtn.style.display = 'inline-flex';
                if (stopBtn) stopBtn.style.display = 'none';
                break;
        }
    }

    updateTranscript(transcript) {
        const transcriptText = document.getElementById('transcript-text');
        if (transcriptText) {
            transcriptText.textContent = `Vous : "${transcript}"`;
        }
    }

    showSuccess(message) {
        const notification = document.createElement('div');
        notification.className = 'success-notification';
        notification.innerHTML = `
            <div class="notification-content">
                <i class="fas fa-check-circle"></i>
                <span>${message}</span>
            </div>
        `;

        notification.style.cssText = `
            position: fixed;
            top: 20px;
            right: 20px;
            background: linear-gradient(135deg, #56ab2f 0%, #a8e063 100%);
            color: white;
            padding: 1rem 1.5rem;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.3);
            z-index: 1000;
            animation: slideIn 0.3s ease-out;
        `;

        document.body.appendChild(notification);

        setTimeout(() => {
            notification.remove();
        }, 3000);
    }

    showError(message) {
        const notification = document.createElement('div');
        notification.className = 'error-notification';
        notification.innerHTML = `
            <div class="notification-content">
                <i class="fas fa-exclamation-triangle"></i>
                <span>${message}</span>
            </div>
        `;

        notification.style.cssText = `
            position: fixed;
            top: 20px;
            right: 20px;
            background: linear-gradient(135deg, #eb3349 0%, #f45c43 100%);
            color: white;
            padding: 1rem 1.5rem;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.3);
            z-index: 1000;
            animation: slideIn 0.3s ease-out;
        `;

        document.body.appendChild(notification);

        setTimeout(() => {
            notification.remove();
        }, 5000);
    }

    showSuggestions(suggestions) {
        if (suggestions && suggestions.length > 0) {
            const suggestionText = `Exemples valides : ${suggestions.join(', ')}`;
            this.showError(suggestionText);
        }
    }
}

// Mode Fallback pour Firefox/Safari
// VERSION AM√âLIOR√âE : √âcoute continue via MediaRecorder + Whisper (backend)
class FallbackRecognitionManager {
    constructor() {
        this.mediaRecorder = null;
        this.audioStream = null;
        this.isListening = false;
        this.isPaused = false;
        this.processingResponse = false;
    }

    init() {
        console.log('‚úÖ Mode fallback : √âcoute continue Firefox (Whisper backend)');
    }

    // ‚úÖ Pause/reprise (compatible avec l'API existante)
    pauseRecognition() {
        console.log('‚è∏Ô∏è Reconnaissance mise en pause (fallback)');
        this.isPaused = true;

        // ‚úÖ FIREFOX : Log pour debug
        console.log('ü¶ä Firefox : √âtat pause activ√© - isListening:', this.isListening);
    }

    resumeRecognition() {
        console.log('‚ñ∂Ô∏è Reconnaissance reprise (fallback)');
        this.isPaused = false;

        // ‚úÖ FIREFOX : V√©rifier si on doit red√©marrer l'√©coute
        if (!this.isListening) {
            console.log('ü¶ä Firefox : Red√©marrage n√©cessaire apr√®s reprise');
            this.startContinuousSpeech();
        } else {
            console.log('ü¶ä Firefox : √âcoute d√©j√† active, reprise simple');
        }
    }

    // ‚úÖ NOUVEAU : Gestion intelligente de l'arr√™t audio pour Firefox uniquement
    handleAudioStop() {
        console.log('üîá Audio arr√™t√© - Gestion Firefox (logique sp√©cifique)');

        // ‚úÖ FIREFOX : Gestion sp√©ciale des √©tats en pause
        if (this.isPaused) {
            console.log('ü¶ä Firefox : Reprise depuis pause (audio arr√™t√©)');
            this.isPaused = false;
            // Si d√©j√† en √©coute, juste reprendre
            if (this.isListening) {
                console.log('ü¶ä Firefox : √âcoute d√©j√† active, reprise simple');
                return;
            }
        }

        // ‚úÖ LOGIQUE FIREFOX : Arr√™ter et red√©marrer proprement
        if (this.mediaRecorder && this.isListening) {
            console.log('ü¶ä Firefox : Arr√™t pour audio (logique Firefox)');

            // Arr√™ter proprement
            this.stopContinuousSpeech();

            // ‚úÖ FIREFOX : Red√©marrage imm√©diat pour √©viter la pause
            setTimeout(() => {
                console.log('ü¶ä Firefox : Red√©marrage imm√©diat apr√®s arr√™t audio');
                this.isPaused = false; // S'assurer qu'on n'est pas en pause
                this.startContinuousSpeech();
            }, 500); // R√©duire √† 0.5 seconde pour plus de r√©activit√©
        } else if (!this.isListening) {
            console.log('ü¶ä Firefox : Red√©marrage direct (pas d\'arr√™t n√©cessaire)');
            this.isPaused = false;
            this.startContinuousSpeech();
        } else {
            console.log('ü¶ä Firefox : Pas de MediaRecorder actif');
        }
    }

    async startContinuousSpeech() {
        // ‚úÖ FIREFOX : Logique simple sans interf√©rer avec Chrome
        if (this.isListening) {
            console.log('‚ö†Ô∏è Firefox : √âcoute d√©j√† active');
            return;
        }

        // ‚úÖ FIREFOX : Nettoyer l'√©tat pr√©c√©dent si n√©cessaire
        if (this.mediaRecorder && this.mediaRecorder.state === 'inactive') {
            console.log('ü¶ä Firefox : Nettoyage √©tat pr√©c√©dent');
            this.mediaRecorder = null;
        }

        try {
            console.log('üé§ D√©marrage √©coute continue (fallback - Whisper)');

            // ‚úÖ Obtenir acc√®s au microphone avec configuration optimis√©e
            this.audioStream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true,
                    sampleRate: 48000,  // ‚úÖ CORRECTION : 48kHz pour WEBM OPUS
                    channelCount: 1,    // ‚úÖ CORRECTION : Mono
                    sampleSize: 16,     // ‚úÖ CORRECTION : 16-bit
                    latency: 0.01       // ‚úÖ CORRECTION : Latence r√©duite
                }
            });

            // ‚úÖ Cr√©er MediaRecorder
            const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
                ? 'audio/webm;codecs=opus'
                : 'audio/webm';

            this.mediaRecorder = new MediaRecorder(this.audioStream, { mimeType });

            // ‚úÖ Traiter chaque chunk audio
            this.mediaRecorder.ondataavailable = async (event) => {
                if (event.data.size > 0 && this.isListening && !this.isPaused) {
                    await this.transcribeChunk(event.data);
                }
            };

            this.mediaRecorder.onerror = (error) => {
                console.error('‚ùå Erreur MediaRecorder:', error);
            };

            // ‚úÖ AM√âLIORATION : Chunks de 3 secondes pour meilleure qualit√©
            this.mediaRecorder.start(3000);
            this.isListening = true;

            console.log('‚úÖ √âcoute continue d√©marr√©e (chunks de 3s)');

        } catch (error) {
            console.error('‚ùå Erreur acc√®s microphone:', error);
            alert('Erreur : Impossible d\'acc√©der au microphone.\nV√©rifiez les permissions.');
        }
    }

    stopContinuousSpeech() {
        if (this.mediaRecorder && this.isListening) {
            console.log('üõë Arr√™t √©coute continue (fallback)');
            this.mediaRecorder.stop();
            this.isListening = false;
        }

        if (this.audioStream) {
            this.audioStream.getTracks().forEach(track => track.stop());
            this.audioStream = null;
        }
    }

    async transcribeChunk(audioBlob) {
        if (this.processingResponse) {
            console.log('‚è≠Ô∏è Chunk ignor√© (traitement en cours)');
            return;
        }

        // ‚úÖ FILTRE : Ignorer les chunks trop petits (bruit de fond)
        if (audioBlob.size < 5000) {
            console.log('üîá Chunk trop petit ignor√©:', audioBlob.size, 'bytes');
            return;
        }

        // ‚úÖ FILTRE : V√©rifier si l'audio contient de la parole
        const hasSpeech = await this.detectSpeech(audioBlob);
        if (!hasSpeech) {
            console.log('üîá Chunk silencieux ignor√©');
            return;
        }

        try {
            console.log('ü¶ä Firefox : Transcription chunk audio avec parole d√©tect√©e');
            console.log(`üîç DEBUG: Taille chunk: ${audioBlob.size} bytes`);
            console.log(`üîç DEBUG: Type chunk: ${audioBlob.type}`);

            // ‚úÖ APPROCHE FIREFOX : Envoyer directement au serveur
            await this.transcribeWithServer(audioBlob);

        } catch (error) {
            console.error('‚ùå Erreur transcription chunk:', error);
        }
    }

    // ‚úÖ NOUVELLE M√âTHODE : D√©tection de parole basique
    async detectSpeech(audioBlob) {
        try {
            // Cr√©er un AudioContext pour analyser l'audio
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const arrayBuffer = await audioBlob.arrayBuffer();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

            // Analyser les donn√©es audio
            const channelData = audioBuffer.getChannelData(0);
            const length = channelData.length;

            // Calculer le volume RMS (Root Mean Square)
            let sum = 0;
            for (let i = 0; i < length; i++) {
                sum += channelData[i] * channelData[i];
            }
            const rms = Math.sqrt(sum / length);

            // ‚úÖ AM√âLIORATION : Seuil plus sensible pour question 0
            const speechThreshold = 0.005; // R√©duire de 0.01 √† 0.005
            const hasSpeech = rms > speechThreshold;

            console.log(`üîç DEBUG: RMS audio: ${rms.toFixed(4)}, Seuil: ${speechThreshold}, Parole: ${hasSpeech}`);

            audioContext.close();
            return hasSpeech;

        } catch (error) {
            console.warn('‚ö†Ô∏è Erreur d√©tection parole:', error);
            // En cas d'erreur, consid√©rer qu'il y a de la parole
            return true;
        }
    }

    // ‚úÖ NOUVELLE M√âTHODE : Transcription avec Web Speech API (approche unmute.sh)
    async transcribeWithWebSpeech(audioBlob) {
        return new Promise((resolve, reject) => {
            try {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                const recognition = new SpeechRecognition();

                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'fr-FR';
                recognition.maxAlternatives = 1;

                recognition.onresult = (event) => {
                    const transcript = event.results[0][0].transcript.trim();
                    console.log('üìù Transcription Web Speech:', transcript);

                    if (transcript) {
                        this.handleSpeechResult(transcript);
                    }
                    resolve(transcript);
                };

                recognition.onerror = (error) => {
                    console.error('‚ùå Erreur Web Speech:', error);
                    reject(error);
                };

                recognition.onend = () => {
                    console.log('‚úÖ Web Speech termin√©');
                };

                // D√©marrer la reconnaissance
                recognition.start();

            } catch (error) {
                console.error('‚ùå Erreur initialisation Web Speech:', error);
                reject(error);
            }
        });
    }

    // ‚úÖ M√âTHODE FALLBACK : Transcription avec serveur
    // ‚úÖ FEEDBACK VISUEL Firefox (corrig√©)
    showVisualFeedback(transcript) {
        // Supprimer les anciens feedbacks
        const existingFeedback = document.querySelector('.firefox-feedback');
        if (existingFeedback) {
            existingFeedback.remove();
        }

        // Cr√©er un √©l√©ment de feedback visuel
        const feedback = document.createElement('div');
        feedback.className = 'firefox-feedback';
        feedback.style.cssText = `
            position: fixed;
            top: 20px;
            right: 20px;
            background: linear-gradient(135deg, #4CAF50 0%, #45a049 100%);
            color: white;
            padding: 12px 18px;
            border-radius: 8px;
            font-size: 14px;
            font-weight: 500;
            z-index: 10000;
            box-shadow: 0 4px 12px rgba(0,0,0,0.3);
            animation: slideInRight 0.3s ease-out;
            max-width: 300px;
            word-wrap: break-word;
        `;

        feedback.innerHTML = `
            <div style="display: flex; align-items: center; gap: 8px;">
                <i class="fas fa-microphone" style="color: #fff; font-size: 16px;"></i>
                <span><strong>Firefox:</strong> "${transcript}"</span>
            </div>
        `;

        // Ajouter l'animation CSS si pas d√©j√† pr√©sente
        if (!document.querySelector('#firefox-feedback-styles')) {
            const style = document.createElement('style');
            style.id = 'firefox-feedback-styles';
            style.textContent = `
                @keyframes slideInRight {
                    from { transform: translateX(100%); opacity: 0; }
                    to { transform: translateX(0); opacity: 1; }
                }
                @keyframes slideOutRight {
                    from { transform: translateX(0); opacity: 1; }
                    to { transform: translateX(100%); opacity: 0; }
                }
            `;
            document.head.appendChild(style);
        }

        document.body.appendChild(feedback);

        // Supprimer apr√®s 4 secondes avec animation
        setTimeout(() => {
            if (feedback.parentNode) {
                feedback.style.animation = 'slideOutRight 0.3s ease-in';
                setTimeout(() => {
                    if (feedback.parentNode) {
                        feedback.parentNode.removeChild(feedback);
                    }
                }, 300);
            }
        }, 4000);
    }

    async transcribeWithServer(audioBlob) {
        try {
            console.log('üì§ Envoi chunk audio vers serveur...');

            const formData = new FormData();
            formData.append('audio', audioBlob);
            formData.append('session_id', window.sessionId);
            formData.append('question_num', window.currentQuestion);

            const response = await fetch('/api/transcribe_chunk', {
                method: 'POST',
                body: formData,
                headers: {
                    'Accept': 'application/json'
                }
            });

            console.log(`üì° R√©ponse serveur: ${response.status} `);

            if (!response.ok) {
                const errorText = await response.text();
                console.warn('‚ö†Ô∏è Erreur serveur transcription:', response.status, errorText);
                return;
            }

            // ‚úÖ GESTION D'ERREUR : V√©rifier le content-type
            const contentType = response.headers.get('content-type');
            if (!contentType || !contentType.includes('application/json')) {
                const responseText = await response.text();
                console.warn('‚ö†Ô∏è R√©ponse non-JSON re√ßue:', responseText);
                return;
            }

            const result = await response.json();
            console.log('üìù R√©sultat serveur:', result);

            if (result.success && result.transcript && result.transcript.trim()) {
                const transcript = result.transcript.trim();
                console.log('üìù Transcription serveur:', transcript);

                // ‚úÖ FILTRE : Ignorer les transcriptions trop courtes ou parasites
                if (transcript.length < 2) {
                    console.log('üîá Transcription trop courte ignor√©e:', transcript);
                    return;
                }

                // ‚úÖ FEEDBACK VISUEL Firefox
                this.showVisualFeedback(transcript);

                this.handleSpeechResult(transcript);
            } else if (result.success && result.fallback) {
                console.log('ü¶ä Firefox : Fallback activ√© - transcription vide ignor√©e');
                console.log('ü¶ä Firefox : Continue d\'√©couter...');
                // ‚úÖ IGNORER les transcriptions vides du fallback
                return;
            } else {
                console.log('üìù Aucune transcription valide re√ßue');
                console.log('üìù R√©sultat complet:', result);
            }

        } catch (error) {
            console.error('‚ùå Erreur transcription serveur:', error);
        }
    }

    handleSpeechResult(transcript) {
        // ‚úÖ M√äME LOGIQUE que SpeechRecognitionManager
        const text = transcript.toLowerCase().trim();

        // Filtrage des r√©sultats parasites
        if (text.length > 30) {
            console.log('‚ö†Ô∏è REJET√â : Texte trop long');
            return;
        }

        if (/question\s+\d+/.test(text)) {
            console.log('‚ö†Ô∏è REJET√â : Contient "question X"');
            return;
        }

        console.log('‚úÖ ACCEPT√â :', text);

        // Arr√™ter l'audio de la question si en cours
        if (window.stopAudioOnSpeech) {
            window.stopAudioOnSpeech();
        }

        // Traiter la r√©ponse
        this.processVoiceResponse(text);
    }

    async processVoiceResponse(transcript) {
        if (this.processingResponse) {
            console.log('‚è≠Ô∏è D√©j√† en cours de traitement');
            return;
        }

        this.processingResponse = true;

        try {
            const response = await fetch('/api/process_voice', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    session_id: window.sessionId,
                    question_num: window.currentQuestion,
                    transcript: transcript
                })
            });

            const result = await response.json();

            if (result.valid) {
                console.log('‚úÖ R√©ponse valid√©e:', result.response_text);

                if (result.is_complete) {
                    setTimeout(() => {
                        window.location.href = `/ resultat / ${window.sessionId} `;
                    }, 1500);
                } else if (result.next_question && window.questionnaireManager) {
                    setTimeout(() => {
                        window.questionnaireManager.loadQuestion(result.next_question);
                    }, 1500);
                }
            } else {
                console.log('‚ùå R√©ponse non reconnue');
            }

        } catch (error) {
            console.error('‚ùå Erreur traitement r√©ponse:', error);
        } finally {
            setTimeout(() => {
                this.processingResponse = false;
            }, 1000);
        }
    }

    // ‚úÖ M√©thodes de compatibilit√© (anciennes, pour ne pas casser l'UI existante)
    async startRecording() {
        // Rediriger vers √©coute continue
        await this.startContinuousSpeech();
    }

    stopRecording() {
        // Rediriger vers arr√™t √©coute continue
        this.stopContinuousSpeech();
    }

    updateUI(state) {
        const recorderBtn = document.getElementById('recorder-btn');
        const recordingStatus = document.getElementById('recording-status');

        if (state === 'recording') {
            if (recorderBtn) {
                recorderBtn.innerHTML = '<i class="fas fa-stop"></i><span>üî¥ Arr√™ter</span>';
                recorderBtn.classList.add('recording');
            }
            if (recordingStatus) {
                recordingStatus.style.display = 'block';
            }
        } else {
            if (recorderBtn) {
                recorderBtn.innerHTML = '<i class="fas fa-microphone"></i><span>üé§ Cliquer pour parler</span>';
                recorderBtn.classList.remove('recording');
            }
            if (recordingStatus) {
                recordingStatus.style.display = 'none';
            }
        }
    }

    showSuccess(message) {
        const notification = document.createElement('div');
        notification.className = 'success-notification';
        notification.innerHTML = `
            < div class="notification-content" >
                <i class="fas fa-check-circle"></i>
                <span>${message}</span>
            </div >
            `;

        notification.style.cssText = `
        position: fixed;
        top: 20px;
        right: 20px;
        background: linear - gradient(135deg, #56ab2f 0 %, #a8e063 100 %);
        color: white;
        padding: 1rem 1.5rem;
        border - radius: 8px;
        box - shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
        z - index: 1000;
        animation: slideIn 0.3s ease - out;
        `;

        document.body.appendChild(notification);

        setTimeout(() => {
            notification.remove();
        }, 3000);
    }

    showError(message) {
        const notification = document.createElement('div');
        notification.className = 'error-notification';
        notification.innerHTML = `
            < div class="notification-content" >
                <i class="fas fa-exclamation-triangle"></i>
                <span>${message}</span>
            </div >
            `;

        notification.style.cssText = `
        position: fixed;
        top: 20px;
        right: 20px;
        background: linear - gradient(135deg, #eb3349 0 %, #f45c43 100 %);
        color: white;
        padding: 1rem 1.5rem;
        border - radius: 8px;
        box - shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
        z - index: 1000;
        animation: slideIn 0.3s ease - out;
        `;

        document.body.appendChild(notification);

        setTimeout(() => {
            notification.remove();
        }, 5000);
    }

    // ‚úÖ SUPPRIM√â : Indicateur visuel complexe non n√©cessaire
    // La logique Firefox est maintenant simple et directe
}

// Initialisation globale
let speechManager = null;
let fallbackManager = null;

// Fonctions globales pour l'interface
function startContinuousSpeech() {
    if (speechManager) {
        speechManager.startContinuousSpeech();
    } else if (fallbackManager) {
        // ‚úÖ Firefox utilise aussi l'√©coute continue maintenant
        fallbackManager.startContinuousSpeech();
    }
}

function stopContinuousSpeech() {
    if (speechManager) {
        speechManager.stopContinuousSpeech();
    } else if (fallbackManager) {
        // ‚úÖ Firefox peut aussi arr√™ter l'√©coute continue
        fallbackManager.stopContinuousSpeech();
    }
}

function startRecording() {
    if (fallbackManager) {
        // ‚úÖ Compatibilit√© : rediriger vers √©coute continue
        if (fallbackManager.isListening) {
            fallbackManager.stopContinuousSpeech();
        } else {
            fallbackManager.startContinuousSpeech();
        }
    }
}

// ‚úÖ NOUVELLE FONCTION : Gestion intelligente de l'arr√™t audio
function handleAudioStop() {
    console.log('üîá Gestion globale de l\'arr√™t audio');

    if (speechManager) {
        console.log('üåê Chrome : Gestion arr√™t audio');
        speechManager.handleAudioStop();
    } else if (fallbackManager) {
        console.log('ü¶ä Firefox : Gestion arr√™t audio');
        fallbackManager.handleAudioStop();
    }
}

// ‚úÖ D√âTECTION AM√âLIOR√âE des navigateurs
const isWebSpeechSupported = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;
const userAgent = navigator.userAgent.toLowerCase();
const isFirefox = userAgent.includes('firefox');
const isChrome = userAgent.includes('chrome') && !userAgent.includes('edg');
const isSafari = userAgent.includes('safari') && !userAgent.includes('chrome');
const isEdge = userAgent.includes('edg');

console.log('üîç D√©tection navigateur am√©lior√©e:');
console.log('  - User Agent:', userAgent);
console.log('  - Web Speech API support√©e:', isWebSpeechSupported);
console.log('  - D√©tect√© Firefox:', isFirefox);
console.log('  - D√©tect√© Chrome:', isChrome);
console.log('  - D√©tect√© Safari:', isSafari);
console.log('  - D√©tect√© Edge:', isEdge);

// Initialisation au chargement de la page
document.addEventListener('DOMContentLoaded', function () {
    console.log('üìÑ DOMContentLoaded - Initialisation des managers');

    // ‚úÖ CR√âER les managers maintenant que le DOM est pr√™t
    managerType = createSpeechManagers();

    // ‚úÖ ASSIGNER aux variables globales
    window.speechManager = speechManager;
    window.fallbackManager = fallbackManager;

    console.log('‚úÖ Managers cr√©√©s:', {
        speechManager: !!speechManager,
        fallbackManager: !!fallbackManager,
        type: managerType
    });

    window.loadQuestion = function (num) {
        if (window.questionnaireManager) {
            window.questionnaireManager.loadQuestion(num);
        }
    };
});

// ‚úÖ CR√âATION INTELLIGENTE des managers
function createSpeechManagers() {
    // Priorit√© 1: Chrome/Edge avec Web Speech API
    if ((isChrome || isEdge) && isWebSpeechSupported) {
        console.log('üåê Chrome/Edge avec Web Speech API ‚Üí Mode Web Speech');
        speechManager = new SpeechRecognitionManager();
        fallbackManager = null;
        return 'web_speech';
    }

    // Priorit√© 2: Firefox/Safari ou navigateurs sans Web Speech API
    if (isFirefox || isSafari || !isWebSpeechSupported) {
        console.log('ü¶ä Firefox/Safari ou sans Web Speech ‚Üí Mode Fallback');
        fallbackManager = new FallbackRecognitionManager();
        speechManager = null;
        return 'fallback';
    }

    // Fallback par d√©faut
    console.log('‚ùì Navigateur inconnu ‚Üí Mode Fallback par d√©faut');
    fallbackManager = new FallbackRecognitionManager();
    speechManager = null;
    return 'fallback';
}

// ‚úÖ CR√âATION DIFF√âR√âE des managers (apr√®s DOMContentLoaded)
let managerType = null;

// ‚úÖ ASSIGNATION des variables globales
window.sessionId = new URLSearchParams(window.location.search).get('session_id');
window.currentQuestion = 1;

// ‚úÖ EXPOSER les fonctions globales
window.handleAudioStop = handleAudioStop;

// ‚úÖ FONCTION D'INITIALISATION AM√âLIOR√âE
window.initSpeechRecognition = function () {
    console.log('üîß initSpeechRecognition appel√©e');
    console.log('üîç DEBUG: speechManager:', !!window.speechManager);
    console.log('üîç DEBUG: fallbackManager:', !!window.fallbackManager);
    console.log('üîç DEBUG: managerType:', managerType);

    if (window.speechManager) {
        console.log('üåê Chrome : Initialisation SpeechRecognitionManager');
        window.speechManager.init();
    } else if (window.fallbackManager) {
        console.log('ü¶ä Firefox : Initialisation FallbackRecognitionManager');
        window.fallbackManager.init();
        console.log('üöÄ Firefox : FallbackRecognitionManager initialis√©');
    } else {
        console.error('‚ùå Aucun manager disponible !');
        console.error('‚ùå V√©rifiez que DOMContentLoaded a √©t√© d√©clench√©');
    }
};